To complete this project was required to clean, organise and manage data in such a way that let us perform analysis in a forecaster basis using data collected from the Survey of Professional Forecasters (SPF), part of the Philadelphia Federal Reserve. 

Task 1:
The first task was required to convert the housing data in order to graphically analyse the forecasters results, using average per quarter and compare with the actual most recent results
Analysis:
Although there aren't many perfectly accurate forecasts in the dataset, it's noticeable that between 2003 and 2006, the gap between forecasted and actual values is significantly larger compared to the rest of the timeframe. Several factors could explain this. In the early 2000s, the widespread adoption of computers and advanced forecasting tools was still underway. As a result, forecasters may have had limited access to reliable equipment or statistical software, which could have contributed to larger margins of error. Additionally, this period coincided with the housing boom that ultimately led to the 2008 financial crisis. The number of homes being built surged, and this unpredictability may have made accurate forecasting more difficult. Interestingly, the number of homes built began to decline in 2006, even before the crash officially hit. This decline could be seen as a leading indicator of the housing bubble bursting. During this period of contraction, the difference between forecasts and actual builds narrowed, possibly due to more cautious behavior in the housing market. After the 2008 crash, the market began to stabilize, and so did the number of houses being built. This may have been due to increased awareness around financial responsibility—people were less likely to purchase homes they couldn't afford, which had been a key factor in the housing crisis. As a result, forecasters may have found it easier to make accurate predictions in a more rational market environment. Lastly, improvements in technology and greater access to powerful computing tools likely contributed to the increased forecasting accuracy observed in the post-crisis years. Better software, data availability, and computational resources made it easier for analysts to produce more reliable forecasts.

Task 2: 
Using the same datasets in the previous task 

Section A)
#The standard deviation of forecast errors across industries is 0.0935, meaning forecasts are not always spot on but fairly close. Industry 1 has an error of 0.0943, Industry 2 is 0.0953, and Industry 3 is 0.0901. The differences are small, but some industries seem to make slightly better predictions than others.
Looking at the graph, we can see that forecasts often miss the actual values—sometimes too high, sometimes too low. The errors change over time, showing that predictions are not always stable. To improve accuracy, we might need better forecasting methods, using more data or improved models.

Section B)
